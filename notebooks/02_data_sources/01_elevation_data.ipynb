{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation Data Access and Processing\n",
    "## Accessing Public Digital Elevation Models for EEMT Analysis\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Access elevation data from multiple public sources (3DEP, OpenTopography, Global DEMs)\n",
    "- Understand different DEM types, resolutions, and coordinate systems\n",
    "- Validate and quality-control elevation datasets\n",
    "- Process DEMs for EEMT calculations\n",
    "- Visualize topographic data effectively\n",
    "\n",
    "**Prerequisites:**\n",
    "- Basic understanding of GIS concepts\n",
    "- Familiarity with coordinate reference systems\n",
    "- Python geospatial libraries (rasterio, geopandas)\n",
    "\n",
    "**Estimated Time:** 40 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and package setup\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add utilities to path\n",
    "sys.path.append('../utilities')\n",
    "\n",
    "# Core scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Geospatial libraries\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "import contextily as ctx\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, FloatSlider, Dropdown, IntSlider\n",
    "\n",
    "# Custom utilities\n",
    "from data_access import (\n",
    "    download_sample_dem, download_opentopo_dem, validate_dataset, \n",
    "    print_validation_report, ensure_output_directory\n",
    ")\n",
    "\n",
    "# Configure display\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overview of Elevation Data Sources\n",
    "\n",
    "### 2.1 Available Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overview table of elevation data sources\n",
    "elevation_sources = [\n",
    "    {\n",
    "        'Source': 'USGS 3DEP',\n",
    "        'Resolution': '1m, 10m, 30m',\n",
    "        'Coverage': 'United States',\n",
    "        'API': 'Yes',\n",
    "        'Best_For': 'High-resolution US analysis',\n",
    "        'Data_Type': 'Lidar-derived DSM/DTM',\n",
    "        'Vertical_Accuracy': '¬±0.1-0.5m',\n",
    "        'Format': 'Cloud-Optimized GeoTIFF'\n",
    "    },\n",
    "    {\n",
    "        'Source': 'OpenTopography SRTM GL1',\n",
    "        'Resolution': '30m (~1 arc-second)',\n",
    "        'Coverage': 'Global (60¬∞N-56¬∞S)',\n",
    "        'API': 'Yes',\n",
    "        'Best_For': 'Global analysis',\n",
    "        'Data_Type': 'Radar interferometry',\n",
    "        'Vertical_Accuracy': '¬±16m',\n",
    "        'Format': 'GeoTIFF'\n",
    "    },\n",
    "    {\n",
    "        'Source': 'OpenTopography ALOS',\n",
    "        'Resolution': '30m',\n",
    "        'Coverage': 'Global',\n",
    "        'API': 'Yes', \n",
    "        'Best_For': 'Global high-quality',\n",
    "        'Data_Type': 'Optical stereo',\n",
    "        'Vertical_Accuracy': '¬±5m',\n",
    "        'Format': 'GeoTIFF'\n",
    "    },\n",
    "    {\n",
    "        'Source': 'Copernicus DEM',\n",
    "        'Resolution': '30m, 90m',\n",
    "        'Coverage': 'Global',\n",
    "        'API': 'Via Copernicus Data Space',\n",
    "        'Best_For': 'Recent global data',\n",
    "        'Data_Type': 'TanDEM-X radar',\n",
    "        'Vertical_Accuracy': '¬±4m',\n",
    "        'Format': 'GeoTIFF'\n",
    "    },\n",
    "    {\n",
    "        'Source': 'FABDEM',\n",
    "        'Resolution': '30m', \n",
    "        'Coverage': 'Global',\n",
    "        'API': 'Via Google Earth Engine',\n",
    "        'Best_For': 'Forest-corrected terrain',\n",
    "        'Data_Type': 'Forest-removed SRTM',\n",
    "        'Vertical_Accuracy': '¬±2m (forest areas)',\n",
    "        'Format': 'GeoTIFF'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "sources_df = pd.DataFrame(elevation_sources)\n",
    "\n",
    "# Create interactive table\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=list(sources_df.columns),\n",
    "        fill_color='lightblue',\n",
    "        align='left',\n",
    "        font=dict(size=12, color='black')\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[sources_df[col] for col in sources_df.columns],\n",
    "        fill_color='white',\n",
    "        align='left',\n",
    "        font=dict(size=11)\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Public Elevation Data Sources for EEMT Analysis',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üìä Key Selection Criteria:\")\n",
    "print(\"   üèîÔ∏è  Resolution: Higher resolution for detailed topographic analysis\")\n",
    "print(\"   üåç Coverage: Global vs regional availability\")\n",
    "print(\"   üéØ Accuracy: Vertical accuracy for your application requirements\")\n",
    "print(\"   üîÑ API Access: Programmatic download capabilities\")\n",
    "print(\"   üíæ Format: Cloud-optimized formats for efficient processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Study Area Selection\n",
    "\n",
    "### 3.1 Geographic Area Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some example study areas\n",
    "study_areas = {\n",
    "    'Arizona Sky Islands': {\n",
    "        'bbox': [-110.5, 32.0, -110.0, 32.5],\n",
    "        'description': 'Diverse topography with elevation range 800-2800m',\n",
    "        'recommended_source': 'USGS 3DEP',\n",
    "        'resolution': '10m'\n",
    "    },\n",
    "    'Colorado Front Range': {\n",
    "        'bbox': [-105.5, 40.0, -105.0, 40.5],\n",
    "        'description': 'Mountain terrain with alpine-desert gradient',\n",
    "        'recommended_source': 'USGS 3DEP', \n",
    "        'resolution': '10m'\n",
    "    },\n",
    "    'Italian Alps': {\n",
    "        'bbox': [10.5, 46.0, 11.0, 46.5],\n",
    "        'description': 'High-relief European mountain terrain',\n",
    "        'recommended_source': 'Copernicus DEM',\n",
    "        'resolution': '30m'\n",
    "    },\n",
    "    'Australian Outback': {\n",
    "        'bbox': [133.0, -24.0, 133.5, -23.5],\n",
    "        'description': 'Arid landscape with low relief',\n",
    "        'recommended_source': 'SRTM GL1',\n",
    "        'resolution': '30m'\n",
    "    },\n",
    "    'Custom Area': {\n",
    "        'bbox': [-111.0, 32.0, -110.5, 32.5],\n",
    "        'description': 'User-defined study area',\n",
    "        'recommended_source': 'SRTM GL1',\n",
    "        'resolution': '30m'\n",
    "    }\n",
    "}\n",
    "\n",
    "def create_study_area_map(area_name):\n",
    "    \"\"\"Create interactive map showing study area\"\"\"\n",
    "    area_info = study_areas[area_name]\n",
    "    bbox = area_info['bbox']\n",
    "    west, south, east, north = bbox\n",
    "    \n",
    "    # Calculate center point\n",
    "    center_lat = (south + north) / 2\n",
    "    center_lon = (west + east) / 2\n",
    "    \n",
    "    # Create folium map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=10,\n",
    "        tiles='OpenStreetMap'\n",
    "    )\n",
    "    \n",
    "    # Add study area rectangle\n",
    "    folium.Rectangle(\n",
    "        bounds=[[south, west], [north, east]],\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fillOpacity=0.2,\n",
    "        popup=f'{area_name}<br>{area_info[\"description\"]}'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Add terrain basemap option\n",
    "    folium.TileLayer(\n",
    "        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr='ESRI World Imagery',\n",
    "        name='Satellite',\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Terrain_Base/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr='ESRI Terrain',\n",
    "        name='Terrain'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "@interact(\n",
    "    study_area=Dropdown(\n",
    "        options=list(study_areas.keys()),\n",
    "        value='Arizona Sky Islands',\n",
    "        description='Study Area:'\n",
    "    )\n",
    ")\n",
    "def select_study_area(study_area):\n",
    "    area_info = study_areas[study_area]\n",
    "    bbox = area_info['bbox']\n",
    "    \n",
    "    print(f\"üìç Selected Study Area: {study_area}\")\n",
    "    print(f\"üì¶ Bounding Box: {bbox}\")\n",
    "    print(f\"üìã Description: {area_info['description']}\")\n",
    "    print(f\"üí° Recommended Source: {area_info['recommended_source']}\")\n",
    "    print(f\"üîç Recommended Resolution: {area_info['resolution']}\")\n",
    "    \n",
    "    # Calculate area dimensions\n",
    "    west, south, east, north = bbox\n",
    "    width_deg = east - west\n",
    "    height_deg = north - south\n",
    "    \n",
    "    # Approximate area in km¬≤ (rough calculation)\n",
    "    lat_avg = (south + north) / 2\n",
    "    km_per_deg_lat = 111.0\n",
    "    km_per_deg_lon = 111.0 * np.cos(np.deg2rad(lat_avg))\n",
    "    \n",
    "    area_km2 = width_deg * km_per_deg_lon * height_deg * km_per_deg_lat\n",
    "    \n",
    "    print(f\"üìê Area: ~{area_km2:.0f} km¬≤ ({width_deg:.3f}¬∞ √ó {height_deg:.3f}¬∞)\")\n",
    "    \n",
    "    # Display map\n",
    "    map_widget = create_study_area_map(study_area)\n",
    "    display(map_widget)\n",
    "    \n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Download and Access\n",
    "\n",
    "### 4.1 Sample DEM Creation and OpenTopography Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample DEM for immediate use\n",
    "print(\"üîÑ Creating sample DEM for immediate analysis...\")\n",
    "sample_dem_path = download_sample_dem(\"../data/elevation\")\n",
    "\n",
    "# Validate the sample DEM\n",
    "print(\"\\nüìä Sample DEM Validation:\")\n",
    "validation = validate_dataset(sample_dem_path, 'elevation')\n",
    "print_validation_report(validation)\n",
    "\n",
    "# Load and display sample DEM\n",
    "with rasterio.open(sample_dem_path) as src:\n",
    "    sample_elevation = src.read(1)\n",
    "    sample_transform = src.transform\n",
    "    sample_crs = src.crs\n",
    "    \n",
    "    # Get extent\n",
    "    bounds = src.bounds\n",
    "    extent = [bounds.left, bounds.right, bounds.bottom, bounds.top]\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Elevation map\n",
    "im1 = axes[0].imshow(sample_elevation, extent=extent, cmap='terrain', origin='upper')\n",
    "axes[0].set_title('Sample DEM - Elevation')\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "plt.colorbar(im1, ax=axes[0], label='Elevation (m)')\n",
    "\n",
    "# Elevation histogram\n",
    "valid_elevation = sample_elevation[~np.isnan(sample_elevation)]\n",
    "axes[1].hist(valid_elevation, bins=50, alpha=0.7, color='brown', edgecolor='black')\n",
    "axes[1].set_xlabel('Elevation (m)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Elevation Distribution')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text\n",
    "stats_text = f'Min: {np.nanmin(valid_elevation):.0f} m\\nMax: {np.nanmax(valid_elevation):.0f} m\\nMean: {np.nanmean(valid_elevation):.0f} m\\nStd: {np.nanstd(valid_elevation):.0f} m'\n",
    "axes[1].text(0.05, 0.95, stats_text, transform=axes[1].transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Sample DEM loaded successfully from: {sample_dem_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 OpenTopography Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_real_dem_data():\n",
    "    \"\"\"\n",
    "    Download real DEM data from OpenTopography\n",
    "    \"\"\"\n",
    "    # Define a small test area (Arizona)\n",
    "    test_bbox = [-110.2, 32.2, -110.0, 32.4]  # Small area for quick download\n",
    "    \n",
    "    print(\"üåç Downloading real elevation data from OpenTopography...\")\n",
    "    print(f\"üì¶ Bounding box: {test_bbox}\")\n",
    "    print(\"‚è±Ô∏è  This may take 30-60 seconds...\")\n",
    "    \n",
    "    try:\n",
    "        # Download SRTM data\n",
    "        srtm_path = download_opentopo_dem(\n",
    "            bbox=test_bbox,\n",
    "            dem_type='SRTMGL1',\n",
    "            output_dir='../data/elevation'\n",
    "        )\n",
    "        \n",
    "        # Validate downloaded data\n",
    "        validation = validate_dataset(srtm_path, 'elevation')\n",
    "        print(\"\\nüìä Downloaded DEM Validation:\")\n",
    "        print_validation_report(validation)\n",
    "        \n",
    "        return srtm_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        print(\"üí° Using sample DEM instead for analysis\")\n",
    "        return sample_dem_path\n",
    "\n",
    "# Interactive download option\n",
    "@interact(\n",
    "    download_real=widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description='Download Real DEM',\n",
    "        button_style='info',\n",
    "        tooltip='Download actual SRTM data (requires internet)'\n",
    "    )\n",
    ")\n",
    "def dem_download_option(download_real):\n",
    "    if download_real:\n",
    "        return download_real_dem_data()\n",
    "    else:\n",
    "        print(\"üì¶ Using sample DEM for analysis\")\n",
    "        print(\"üí° Toggle above to download real data from OpenTopography\")\n",
    "        return sample_dem_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DEM Processing and Analysis\n",
    "\n",
    "### 5.1 Topographic Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topographic_derivatives(elevation_array, pixel_size=30):\n",
    "    \"\"\"\n",
    "    Calculate slope, aspect, and other topographic derivatives\n",
    "    \n",
    "    Parameters:\n",
    "    elevation_array: 2D numpy array of elevation values\n",
    "    pixel_size: Pixel size in meters\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with slope, aspect, hillshade, and other derivatives\n",
    "    \"\"\"\n",
    "    # Calculate gradients\n",
    "    dy, dx = np.gradient(elevation_array, pixel_size)\n",
    "    \n",
    "    # Slope in degrees\n",
    "    slope_rad = np.arctan(np.sqrt(dx**2 + dy**2))\n",
    "    slope_deg = np.rad2deg(slope_rad)\n",
    "    \n",
    "    # Aspect in degrees (0=N, 90=E, 180=S, 270=W)\n",
    "    aspect_rad = np.arctan2(-dx, dy)\n",
    "    aspect_deg = np.rad2deg(aspect_rad)\n",
    "    aspect_deg = (450 - aspect_deg) % 360  # Convert to standard geographic convention\n",
    "    \n",
    "    # Hillshade (simple illumination model)\n",
    "    # Sun elevation = 45¬∞, azimuth = 315¬∞ (NW)\n",
    "    sun_elevation = np.deg2rad(45)\n",
    "    sun_azimuth = np.deg2rad(315)\n",
    "    \n",
    "    hillshade = (np.sin(sun_elevation) * np.cos(slope_rad) +\n",
    "                np.cos(sun_elevation) * np.sin(slope_rad) *\n",
    "                np.cos(sun_azimuth - aspect_rad))\n",
    "    hillshade = np.clip(hillshade, 0, 1) * 255\n",
    "    \n",
    "    # Curvature (second derivatives)\n",
    "    dxx = np.gradient(dx, pixel_size, axis=1)\n",
    "    dyy = np.gradient(dy, pixel_size, axis=0) \n",
    "    dxy = np.gradient(dx, pixel_size, axis=0)\n",
    "    \n",
    "    # Plan curvature (curvature perpendicular to slope direction)\n",
    "    plan_curvature = (dxx * dy**2 - 2 * dxy * dx * dy + dyy * dx**2) / (dx**2 + dy**2 + 1e-10)**1.5\n",
    "    \n",
    "    # Profile curvature (curvature in slope direction)\n",
    "    profile_curvature = (dxx * dx**2 + 2 * dxy * dx * dy + dyy * dy**2) / (dx**2 + dy**2 + 1e-10)**1.5\n",
    "    \n",
    "    return {\n",
    "        'slope': slope_deg,\n",
    "        'aspect': aspect_deg,\n",
    "        'hillshade': hillshade,\n",
    "        'plan_curvature': plan_curvature,\n",
    "        'profile_curvature': profile_curvature,\n",
    "        'dx': dx,\n",
    "        'dy': dy\n",
    "    }\n",
    "\n",
    "# Calculate derivatives for sample DEM\n",
    "print(\"üî¢ Calculating topographic derivatives...\")\n",
    "derivatives = calculate_topographic_derivatives(sample_elevation, pixel_size=100)  # Approximate pixel size\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each derivative\n",
    "plots = [\n",
    "    ('Elevation', sample_elevation, 'terrain'),\n",
    "    ('Slope', derivatives['slope'], 'Reds'), \n",
    "    ('Aspect', derivatives['aspect'], 'hsv'),\n",
    "    ('Hillshade', derivatives['hillshade'], 'gray'),\n",
    "    ('Plan Curvature', derivatives['plan_curvature'], 'RdBu'),\n",
    "    ('Profile Curvature', derivatives['profile_curvature'], 'RdBu')\n",
    "]\n",
    "\n",
    "for i, (title, data, cmap) in enumerate(plots):\n",
    "    im = axes[i].imshow(data, extent=extent, cmap=cmap, origin='upper')\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].set_xlabel('Longitude')\n",
    "    axes[i].set_ylabel('Latitude')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=axes[i], shrink=0.8)\n",
    "    \n",
    "    # Add statistics\n",
    "    valid_data = data[~np.isnan(data)]\n",
    "    if len(valid_data) > 0:\n",
    "        stats_text = f'Range: {np.nanmin(valid_data):.1f} to {np.nanmax(valid_data):.1f}'\n",
    "        axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes,\n",
    "                    verticalalignment='top', fontsize=9,\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nüìä Topographic Derivative Statistics:\")\n",
    "for name, data in derivatives.items():\n",
    "    if name not in ['dx', 'dy']:  # Skip raw gradients\n",
    "        valid_data = data[~np.isnan(data)]\n",
    "        if len(valid_data) > 0:\n",
    "            print(f\"   {name:15}: {np.nanmin(valid_data):8.2f} to {np.nanmax(valid_data):8.2f} (mean: {np.nanmean(valid_data):6.2f})\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"   üèîÔ∏è  Slope: Steepness of terrain (0¬∞ = flat, 90¬∞ = vertical)\")\n",
    "print(\"   üß≠ Aspect: Direction of steepest descent (0¬∞ = North, 180¬∞ = South)\")\n",
    "print(\"   ‚òÄÔ∏è  Hillshade: Illumination simulation for visualization\")\n",
    "print(\"   üìê Plan Curvature: Convergence/divergence of flow (+ = ridges, - = valleys)\")\n",
    "print(\"   üìà Profile Curvature: Acceleration/deceleration of flow (+ = convex, - = concave)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Interactive Topographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    analysis_type=Dropdown(\n",
    "        options=['Slope Distribution', 'Aspect Analysis', 'Elevation Profiles', 'Terrain Classification'],\n",
    "        value='Slope Distribution',\n",
    "        description='Analysis:'\n",
    "    ),\n",
    "    slope_threshold=FloatSlider(\n",
    "        min=0, max=45, step=5, value=15,\n",
    "        description='Slope Threshold (¬∞):'\n",
    "    )\n",
    ")\n",
    "def interactive_topographic_analysis(analysis_type, slope_threshold):\n",
    "    \n",
    "    if analysis_type == 'Slope Distribution':\n",
    "        # Slope distribution analysis\n",
    "        valid_slope = derivatives['slope'][~np.isnan(derivatives['slope'])]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Histogram\n",
    "        ax1.hist(valid_slope, bins=50, alpha=0.7, color='orangered', edgecolor='black')\n",
    "        ax1.axvline(slope_threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {slope_threshold}¬∞')\n",
    "        ax1.set_xlabel('Slope (degrees)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Slope Distribution')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Slope classes\n",
    "        slope_classes = np.digitize(derivatives['slope'], [0, 5, 15, 30, 45, 90])\n",
    "        slope_labels = ['Flat (0-5¬∞)', 'Gentle (5-15¬∞)', 'Moderate (15-30¬∞)', 'Steep (30-45¬∞)', 'Very Steep (45¬∞+)']\n",
    "        \n",
    "        im = ax2.imshow(slope_classes, extent=extent, cmap='Reds', origin='upper')\n",
    "        ax2.set_title('Slope Classification')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        ax2.set_ylabel('Latitude')\n",
    "        \n",
    "        # Calculate percentages\n",
    "        unique, counts = np.unique(slope_classes[~np.isnan(slope_classes)], return_counts=True)\n",
    "        percentages = counts / counts.sum() * 100\n",
    "        \n",
    "        print(f\"üìä Slope Classification Results:\")\n",
    "        for i, (cls, pct) in enumerate(zip(unique, percentages)):\n",
    "            if cls < len(slope_labels):\n",
    "                print(f\"   {slope_labels[int(cls)-1]:15}: {pct:5.1f}%\")\n",
    "        \n",
    "        print(f\"\\nüí° Terrain above {slope_threshold}¬∞: {np.sum(valid_slope > slope_threshold) / len(valid_slope) * 100:.1f}%\")\n",
    "    \n",
    "    elif analysis_type == 'Aspect Analysis':\n",
    "        # Aspect analysis with rose diagram\n",
    "        valid_aspect = derivatives['aspect'][~np.isnan(derivatives['aspect'])]\n",
    "        \n",
    "        # Create rose diagram data\n",
    "        aspect_bins = np.arange(0, 361, 45)  # 8 directions\n",
    "        aspect_counts, _ = np.histogram(valid_aspect, bins=aspect_bins)\n",
    "        \n",
    "        # Convert to radians for polar plot\n",
    "        theta = np.deg2rad(aspect_bins[:-1] + 22.5)  # Center of each bin\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=aspect_counts,\n",
    "            theta=np.rad2deg(theta),\n",
    "            fill='toself',\n",
    "            name='Aspect Distribution'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(visible=True, range=[0, max(aspect_counts)]),\n",
    "                angularaxis=dict(\n",
    "                    tickmode='array',\n",
    "                    tickvals=[0, 45, 90, 135, 180, 225, 270, 315],\n",
    "                    ticktext=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "                )\n",
    "            ),\n",
    "            title='Aspect Rose Diagram',\n",
    "            width=600, height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # Aspect statistics\n",
    "        directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW']\n",
    "        print(f\"üìä Aspect Distribution:\")\n",
    "        for i, (direction, count) in enumerate(zip(directions, aspect_counts)):\n",
    "            percentage = count / aspect_counts.sum() * 100\n",
    "            print(f\"   {direction:3}: {percentage:5.1f}% ({count:4d} pixels)\")\n",
    "    \n",
    "    elif analysis_type == 'Elevation Profiles':\n",
    "        # Extract elevation profiles\n",
    "        height, width = sample_elevation.shape\n",
    "        \n",
    "        # Horizontal profile (middle row)\n",
    "        h_profile = sample_elevation[height//2, :]\n",
    "        h_distance = np.linspace(extent[0], extent[1], width)\n",
    "        \n",
    "        # Vertical profile (middle column)\n",
    "        v_profile = sample_elevation[:, width//2]\n",
    "        v_distance = np.linspace(extent[3], extent[2], height)  # Top to bottom\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # Horizontal profile\n",
    "        ax1.plot(h_distance, h_profile, 'b-', linewidth=2, label='W-E Profile')\n",
    "        ax1.fill_between(h_distance, h_profile, alpha=0.3)\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Elevation (m)')\n",
    "        ax1.set_title('West-East Elevation Profile (Middle Row)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Vertical profile\n",
    "        ax2.plot(v_distance, v_profile, 'r-', linewidth=2, label='N-S Profile')\n",
    "        ax2.fill_between(v_distance, v_profile, alpha=0.3, color='red')\n",
    "        ax2.set_xlabel('Latitude')\n",
    "        ax2.set_ylabel('Elevation (m)')\n",
    "        ax2.set_title('North-South Elevation Profile (Middle Column)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Profile statistics\n",
    "        h_relief = np.nanmax(h_profile) - np.nanmin(h_profile)\n",
    "        v_relief = np.nanmax(v_profile) - np.nanmin(v_profile)\n",
    "        \n",
    "        print(f\"üìè Profile Analysis:\")\n",
    "        print(f\"   W-E Relief: {h_relief:.1f} m\")\n",
    "        print(f\"   N-S Relief: {v_relief:.1f} m\")\n",
    "        print(f\"   Dominant trend: {'W-E' if h_relief > v_relief else 'N-S'}\")\n",
    "    \n",
    "    elif analysis_type == 'Terrain Classification':\n",
    "        # Classify terrain based on slope and curvature\n",
    "        slope = derivatives['slope']\n",
    "        plan_curv = derivatives['plan_curvature']\n",
    "        profile_curv = derivatives['profile_curvature']\n",
    "        \n",
    "        # Define thresholds\n",
    "        slope_thresh = 15  # degrees\n",
    "        curv_thresh = 0.01  # curvature units\n",
    "        \n",
    "        # Classify terrain\n",
    "        terrain_class = np.zeros_like(slope)\n",
    "        \n",
    "        # Flat areas\n",
    "        terrain_class[slope < 5] = 1\n",
    "        \n",
    "        # Ridges (steep + convex profile)\n",
    "        terrain_class[(slope >= slope_thresh) & (profile_curv > curv_thresh)] = 2\n",
    "        \n",
    "        # Valleys (convergent + concave profile)\n",
    "        terrain_class[(plan_curv < -curv_thresh) & (profile_curv < -curv_thresh)] = 3\n",
    "        \n",
    "        # Slopes (moderate slope, low curvature)\n",
    "        terrain_class[(slope >= 5) & (slope < slope_thresh) & \n",
    "                     (np.abs(plan_curv) <= curv_thresh) & \n",
    "                     (np.abs(profile_curv) <= curv_thresh)] = 4\n",
    "        \n",
    "        # Steep slopes\n",
    "        terrain_class[(slope >= slope_thresh) & (terrain_class == 0)] = 5\n",
    "        \n",
    "        # Create custom colormap\n",
    "        colors = ['white', 'lightgreen', 'brown', 'blue', 'orange', 'red']\n",
    "        labels = ['Unclassified', 'Flat', 'Ridge', 'Valley', 'Gentle Slope', 'Steep Slope']\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        im = ax.imshow(terrain_class, extent=extent, origin='upper', cmap='Set1')\n",
    "        ax.set_title('Geomorphological Terrain Classification')\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate class percentages\n",
    "        unique, counts = np.unique(terrain_class[~np.isnan(terrain_class)], return_counts=True)\n",
    "        percentages = counts / counts.sum() * 100\n",
    "        \n",
    "        print(f\"üó∫Ô∏è  Terrain Classification Results:\")\n",
    "        for cls, pct, count in zip(unique, percentages, counts):\n",
    "            if int(cls) < len(labels):\n",
    "                print(f\"   {labels[int(cls)]:15}: {pct:5.1f}% ({count:4d} pixels)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DEM Quality Assessment\n",
    "\n",
    "### 6.1 Data Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_dem_quality(elevation_array, derivatives_dict):\n",
    "    \"\"\"\n",
    "    Assess DEM quality using multiple metrics\n",
    "    \n",
    "    Parameters:\n",
    "    elevation_array: 2D elevation array\n",
    "    derivatives_dict: Dictionary with slope, aspect, etc.\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with quality metrics\n",
    "    \"\"\"\n",
    "    valid_elevation = elevation_array[~np.isnan(elevation_array)]\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'data_completeness': len(valid_elevation) / elevation_array.size * 100,\n",
    "        'elevation_range': np.ptp(valid_elevation),\n",
    "        'elevation_std': np.std(valid_elevation),\n",
    "        'mean_slope': np.nanmean(derivatives_dict['slope']),\n",
    "        'slope_std': np.nanstd(derivatives_dict['slope']),\n",
    "        'terrain_roughness': np.nanstd(derivatives_dict['slope']),\n",
    "        'aspect_uniformity': calculate_aspect_uniformity(derivatives_dict['aspect']),\n",
    "        'noise_level': estimate_noise_level(elevation_array)\n",
    "    }\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "def calculate_aspect_uniformity(aspect_array):\n",
    "    \"\"\"\n",
    "    Calculate aspect uniformity (0 = uniform, 1 = highly variable)\n",
    "    \"\"\"\n",
    "    valid_aspect = aspect_array[~np.isnan(aspect_array)]\n",
    "    \n",
    "    # Convert to unit vectors\n",
    "    aspect_rad = np.deg2rad(valid_aspect)\n",
    "    x_components = np.cos(aspect_rad)\n",
    "    y_components = np.sin(aspect_rad)\n",
    "    \n",
    "    # Calculate vector strength (opposite of uniformity)\n",
    "    mean_x = np.mean(x_components)\n",
    "    mean_y = np.mean(y_components)\n",
    "    vector_strength = np.sqrt(mean_x**2 + mean_y**2)\n",
    "    \n",
    "    return 1 - vector_strength  # Convert to uniformity measure\n",
    "\n",
    "def estimate_noise_level(elevation_array):\n",
    "    \"\"\"\n",
    "    Estimate noise level using high-frequency content\n",
    "    \"\"\"\n",
    "    from scipy import ndimage\n",
    "    \n",
    "    # Apply Laplacian filter to detect noise\n",
    "    laplacian = ndimage.laplace(elevation_array)\n",
    "    noise_estimate = np.nanstd(laplacian)\n",
    "    \n",
    "    return noise_estimate\n",
    "\n",
    "# Assess quality of sample DEM\n",
    "print(\"üîç Assessing DEM Quality...\")\n",
    "quality_metrics = assess_dem_quality(sample_elevation, derivatives)\n",
    "\n",
    "# Create quality report visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Data completeness\n",
    "completeness = quality_metrics['data_completeness']\n",
    "axes[0,0].pie([completeness, 100-completeness], labels=['Valid Data', 'No Data'], \n",
    "              colors=['green', 'red'], autopct='%1.1f%%')\n",
    "axes[0,0].set_title(f'Data Completeness\\n{completeness:.1f}% valid pixels')\n",
    "\n",
    "# Elevation distribution\n",
    "valid_elev = sample_elevation[~np.isnan(sample_elevation)]\n",
    "axes[0,1].hist(valid_elev, bins=50, alpha=0.7, color='brown', edgecolor='black')\n",
    "axes[0,1].set_xlabel('Elevation (m)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].set_title(f'Elevation Distribution\\nRange: {quality_metrics[\"elevation_range\"]:.0f} m')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Slope distribution\n",
    "valid_slope = derivatives['slope'][~np.isnan(derivatives['slope'])]\n",
    "axes[1,0].hist(valid_slope, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1,0].set_xlabel('Slope (degrees)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title(f'Slope Distribution\\nMean: {quality_metrics[\"mean_slope\"]:.1f}¬∞')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Quality metrics summary\n",
    "axes[1,1].axis('off')\n",
    "quality_text = f\"\"\"\n",
    "DEM Quality Assessment\n",
    "{'='*25}\n",
    "\n",
    "Data Completeness: {quality_metrics['data_completeness']:.1f}%\n",
    "Elevation Range: {quality_metrics['elevation_range']:.1f} m\n",
    "Elevation Std Dev: {quality_metrics['elevation_std']:.1f} m\n",
    "Mean Slope: {quality_metrics['mean_slope']:.1f}¬∞\n",
    "Terrain Roughness: {quality_metrics['terrain_roughness']:.2f}\n",
    "Aspect Uniformity: {quality_metrics['aspect_uniformity']:.3f}\n",
    "Noise Level: {quality_metrics['noise_level']:.2f}\n",
    "\n",
    "Quality Rating:\n",
    "\"\"\"\n",
    "\n",
    "# Simple quality rating\n",
    "if quality_metrics['data_completeness'] > 95:\n",
    "    if quality_metrics['noise_level'] < 1.0:\n",
    "        rating = \"Excellent ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\"\n",
    "    else:\n",
    "        rating = \"Good ‚≠ê‚≠ê‚≠ê‚≠ê\"\n",
    "elif quality_metrics['data_completeness'] > 90:\n",
    "    rating = \"Fair ‚≠ê‚≠ê‚≠ê\"\n",
    "else:\n",
    "    rating = \"Poor ‚≠ê‚≠ê\"\n",
    "\n",
    "quality_text += rating\n",
    "\n",
    "axes[1,1].text(0.05, 0.95, quality_text, transform=axes[1,1].transAxes,\n",
    "               fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìã DEM Quality Summary:\")\n",
    "print(f\"   Overall Rating: {rating}\")\n",
    "print(f\"   Primary Strengths: {'High data completeness' if quality_metrics['data_completeness'] > 95 else 'Adequate coverage'}\")\n",
    "print(f\"   Terrain Complexity: {'High' if quality_metrics['terrain_roughness'] > 10 else 'Moderate' if quality_metrics['terrain_roughness'] > 5 else 'Low'}\")\n",
    "print(f\"   Suitable for EEMT: {'Yes' if quality_metrics['data_completeness'] > 90 else 'With limitations'}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "if quality_metrics['data_completeness'] < 95:\n",
    "    print(f\"   ‚Ä¢ Consider gap-filling for missing data\")\n",
    "if quality_metrics['noise_level'] > 2.0:\n",
    "    print(f\"   ‚Ä¢ Apply smoothing filter to reduce noise\")\n",
    "if quality_metrics['elevation_range'] < 100:\n",
    "    print(f\"   ‚Ä¢ Low relief area - topographic effects may be minimal\")\n",
    "if quality_metrics['aspect_uniformity'] > 0.8:\n",
    "    print(f\"   ‚Ä¢ High aspect variability indicates complex terrain\")\n",
    "    \n",
    "print(f\"   ‚Ä¢ DEM suitable for solar radiation modeling: {rating != 'Poor ‚≠ê‚≠ê'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Coordinate Reference Systems\n",
    "\n",
    "### 7.1 CRS Analysis and Reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dem_crs(dem_path):\n",
    "    \"\"\"\n",
    "    Analyze coordinate reference system of DEM\n",
    "    \"\"\"\n",
    "    with rasterio.open(dem_path) as src:\n",
    "        crs_info = {\n",
    "            'crs': src.crs,\n",
    "            'crs_string': str(src.crs),\n",
    "            'bounds': src.bounds,\n",
    "            'transform': src.transform,\n",
    "            'pixel_size': (src.transform[0], -src.transform[4]),\n",
    "            'units': src.crs.linear_units if src.crs else 'unknown'\n",
    "        }\n",
    "        \n",
    "        # Check if geographic or projected\n",
    "        crs_info['is_geographic'] = src.crs.is_geographic if src.crs else None\n",
    "        crs_info['is_projected'] = src.crs.is_projected if src.crs else None\n",
    "        \n",
    "    return crs_info\n",
    "\n",
    "def recommend_projection(bounds, center_lat, center_lon):\n",
    "    \"\"\"\n",
    "    Recommend appropriate projection for study area\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # UTM zone calculation\n",
    "    utm_zone = int((center_lon + 180) / 6) + 1\n",
    "    hemisphere = 'N' if center_lat >= 0 else 'S'\n",
    "    epsg_utm = 32600 + utm_zone if hemisphere == 'N' else 32700 + utm_zone\n",
    "    \n",
    "    recommendations.append({\n",
    "        'name': f'UTM Zone {utm_zone}{hemisphere}',\n",
    "        'epsg': epsg_utm,\n",
    "        'reason': 'Best for local/regional analysis with accurate distances',\n",
    "        'pros': 'Conformal, accurate distances and areas',\n",
    "        'cons': 'Limited to 6¬∞ longitude bands'\n",
    "    })\n",
    "    \n",
    "    # Equal Area projections for large areas\n",
    "    if abs(bounds.right - bounds.left) > 2 or abs(bounds.top - bounds.bottom) > 2:\n",
    "        recommendations.append({\n",
    "            'name': 'Lambert Azimuthal Equal Area',\n",
    "            'epsg': None,\n",
    "            'reason': 'Best for large area analysis requiring accurate areas',\n",
    "            'pros': 'Equal area, good for continental scale',\n",
    "            'cons': 'Shape distortion increases with distance from center'\n",
    "        })\n",
    "    \n",
    "    # Web Mercator for visualization\n",
    "    recommendations.append({\n",
    "        'name': 'Web Mercator',\n",
    "        'epsg': 3857,\n",
    "        'reason': 'Good for web mapping and visualization',\n",
    "        'pros': 'Compatible with web maps, familiar',\n",
    "        'cons': 'Area distortion, not suitable for analysis at high latitudes'\n",
    "    })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Analyze sample DEM CRS\n",
    "print(\"üó∫Ô∏è Analyzing Coordinate Reference System...\")\n",
    "crs_info = analyze_dem_crs(sample_dem_path)\n",
    "\n",
    "print(f\"\\nüìç Current CRS Information:\")\n",
    "print(f\"   CRS: {crs_info['crs_string']}\")\n",
    "print(f\"   Type: {'Geographic' if crs_info['is_geographic'] else 'Projected' if crs_info['is_projected'] else 'Unknown'}\")\n",
    "print(f\"   Units: {crs_info['units']}\")\n",
    "print(f\"   Bounds: W={crs_info['bounds'].left:.3f}, S={crs_info['bounds'].bottom:.3f}, E={crs_info['bounds'].right:.3f}, N={crs_info['bounds'].top:.3f}\")\n",
    "print(f\"   Pixel Size: {crs_info['pixel_size'][0]:.6f} x {crs_info['pixel_size'][1]:.6f} {crs_info['units']}\")\n",
    "\n",
    "# Get center coordinates\n",
    "center_lat = (crs_info['bounds'].bottom + crs_info['bounds'].top) / 2\n",
    "center_lon = (crs_info['bounds'].left + crs_info['bounds'].right) / 2\n",
    "\n",
    "print(f\"   Center: {center_lat:.3f}¬∞N, {center_lon:.3f}¬∞W\")\n",
    "\n",
    "# Get projection recommendations\n",
    "recommendations = recommend_projection(crs_info['bounds'], center_lat, center_lon)\n",
    "\n",
    "print(f\"\\nüéØ Recommended Projections:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n   {i}. {rec['name']}\")\n",
    "    if rec['epsg']:\n",
    "        print(f\"      EPSG: {rec['epsg']}\")\n",
    "    print(f\"      Reason: {rec['reason']}\")\n",
    "    print(f\"      Pros: {rec['pros']}\")\n",
    "    print(f\"      Cons: {rec['cons']}\")\n",
    "\n",
    "# Demonstrate reprojection to UTM\n",
    "print(f\"\\nüîÑ Demonstration: Reprojecting to UTM...\")\n",
    "\n",
    "utm_zone = int((center_lon + 180) / 6) + 1\n",
    "hemisphere = 'N' if center_lat >= 0 else 'S'\n",
    "epsg_utm = 32600 + utm_zone if hemisphere == 'N' else 32700 + utm_zone\n",
    "target_crs = f'EPSG:{epsg_utm}'\n",
    "\n",
    "with rasterio.open(sample_dem_path) as src:\n",
    "    # Calculate transform for reprojection\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, target_crs, src.width, src.height, *src.bounds)\n",
    "    \n",
    "    # Create profile for reprojected raster\n",
    "    kwargs = src.profile.copy()\n",
    "    kwargs.update({\n",
    "        'crs': target_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "    \n",
    "    # Calculate new pixel size\n",
    "    utm_pixel_size = (transform[0], -transform[4])\n",
    "    \n",
    "    print(f\"   Original CRS: {src.crs}\")\n",
    "    print(f\"   Target CRS: {target_crs} (UTM Zone {utm_zone}{hemisphere})\")\n",
    "    print(f\"   Original pixel size: {crs_info['pixel_size'][0]:.6f}¬∞ x {crs_info['pixel_size'][1]:.6f}¬∞\")\n",
    "    print(f\"   UTM pixel size: {utm_pixel_size[0]:.1f}m x {utm_pixel_size[1]:.1f}m\")\n",
    "    print(f\"   Original dimensions: {src.width} x {src.height}\")\n",
    "    print(f\"   UTM dimensions: {width} x {height}\")\n",
    "\n",
    "print(f\"\\nüí° For EEMT Calculations:\")\n",
    "print(f\"   ‚Ä¢ Geographic (WGS84) coordinates work well for DAYMET climate data alignment\")\n",
    "print(f\"   ‚Ä¢ UTM projections provide accurate areas and distances for local analysis\")\n",
    "print(f\"   ‚Ä¢ Choose projection based on your study area size and analysis requirements\")\n",
    "print(f\"   ‚Ä¢ GRASS GIS can handle reprojection automatically during solar radiation calculations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### 8.1 Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=['Data Sources Comparison', 'Resolution vs Coverage Trade-off',\n",
    "                   'Quality Assessment Framework', 'Processing Workflow'],\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"scatter\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# Data sources summary\n",
    "summary_data = [\n",
    "    ['USGS 3DEP', 'US Only', '1-30m', 'Excellent', 'Yes'],\n",
    "    ['SRTM GL1', 'Global', '30m', 'Good', 'Yes'],\n",
    "    ['ALOS World', 'Global', '30m', 'Very Good', 'Yes'],\n",
    "    ['Copernicus', 'Global', '30-90m', 'Very Good', 'Limited'],\n",
    "    ['FABDEM', 'Global', '30m', 'Good*', 'Via GEE']\n",
    "]\n",
    "\n",
    "fig.add_trace(go.Table(\n",
    "    header=dict(values=['Source', 'Coverage', 'Resolution', 'Quality', 'API'],\n",
    "               fill_color='lightblue'),\n",
    "    cells=dict(values=list(zip(*summary_data)),\n",
    "              fill_color='white')\n",
    "), row=1, col=1)\n",
    "\n",
    "# Resolution vs coverage scatter\n",
    "sources = ['3DEP-1m', '3DEP-10m', '3DEP-30m', 'SRTM-30m', 'ALOS-30m', 'COP-30m', 'COP-90m']\n",
    "resolutions = [1, 10, 30, 30, 30, 30, 90]\n",
    "coverage_scores = [1, 1, 1, 10, 10, 10, 10]  # 1=US, 10=Global\n",
    "quality_scores = [10, 9, 8, 6, 8, 8, 7]  # Relative quality\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=resolutions, y=coverage_scores,\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=quality_scores, sizemode='area', sizeref=0.5, color=quality_scores,\n",
    "               colorscale='Viridis'),\n",
    "    text=sources, textposition='top center',\n",
    "    name='Data Sources'\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Resolution (m)\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Coverage (1=US, 10=Global)\", row=1, col=2)\n",
    "\n",
    "# Quality metrics\n",
    "quality_categories = ['Completeness', 'Accuracy', 'Resolution', 'Coverage', 'API Access']\n",
    "current_scores = [90, 85, 70, 95, 80]  # Example scores\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=quality_categories, y=current_scores,\n",
    "    marker_color=['green' if score >= 80 else 'orange' if score >= 60 else 'red' \n",
    "                  for score in current_scores],\n",
    "    name='Quality Scores'\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Score (0-100)\", row=2, col=1)\n",
    "\n",
    "# Processing workflow\n",
    "workflow_steps = ['Download', 'Validate', 'Derivatives', 'Quality Check', 'Ready for EEMT']\n",
    "completion = [100, 100, 100, 100, 100]  # All steps completed\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=workflow_steps, y=completion,\n",
    "    mode='lines+markers',\n",
    "    line=dict(width=4, color='green'),\n",
    "    marker=dict(size=10, color='green'),\n",
    "    name='Workflow Progress'\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Completion (%)\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Elevation Data Analysis Summary',\n",
    "    height=700, width=1200,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"üéØ Key Learning Outcomes Achieved:\")\n",
    "print(\"   ‚úÖ Understand multiple public elevation data sources\")\n",
    "print(\"   ‚úÖ Access and download DEM data programmatically\")\n",
    "print(\"   ‚úÖ Validate data quality and assess fitness for use\")\n",
    "print(\"   ‚úÖ Calculate topographic derivatives (slope, aspect, curvature)\")\n",
    "print(\"   ‚úÖ Understand coordinate reference systems and projections\")\n",
    "print(\"   ‚úÖ Visualize topographic data effectively\")\n",
    "\n",
    "print(\"\\nüí° Best Practices Summary:\")\n",
    "print(\"   üéØ Choose data source based on study area and resolution requirements\")\n",
    "print(\"   üîç Always validate downloaded data before analysis\")\n",
    "print(\"   üìè Consider coordinate reference system for accurate calculations\")\n",
    "print(\"   üó∫Ô∏è  Use topographic derivatives to understand terrain characteristics\")\n",
    "print(\"   ‚öñÔ∏è  Balance resolution, coverage, and computational requirements\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   ‚Üí 02_climate_data.ipynb: Access DAYMET and other climate datasets\")\n",
    "print(\"   ‚Üí ../03_grass_workflows/01_grass_setup.ipynb: GRASS GIS environment setup\")\n",
    "print(\"   ‚Üí ../03_grass_workflows/02_solar_modeling.ipynb: Solar radiation calculations\")\n",
    "print(\"   ‚Üí ../04_calculation_methods/: EEMT calculation implementations\")\n",
    "\n",
    "print(\"\\nüìö Additional Resources:\")\n",
    "print(\"   ‚Ä¢ OpenTopography: https://opentopography.org/\")\n",
    "print(\"   ‚Ä¢ USGS 3DEP: https://www.usgs.gov/3d-elevation-program\")\n",
    "print(\"   ‚Ä¢ Copernicus DEM: https://spacedata.copernicus.eu/\")\n",
    "print(\"   ‚Ä¢ FABDEM: https://data.bris.ac.uk/data/dataset/25wfy0f9ukoge2gs7a5mqpq2j7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercises and Extensions\n",
    "\n",
    "### 9.1 Practice Exercises\n",
    "\n",
    "1. **Local Area Analysis**:\n",
    "   - Download elevation data for your local area\n",
    "   - Calculate topographic derivatives\n",
    "   - Identify dominant terrain features\n",
    "\n",
    "2. **Multi-source Comparison**:\n",
    "   - Download the same area from different sources (SRTM vs ALOS)\n",
    "   - Compare elevation values and topographic derivatives\n",
    "   - Analyze differences and their potential impact on EEMT\n",
    "\n",
    "3. **Resolution Analysis**:\n",
    "   - Resample high-resolution DEM to coarser resolutions\n",
    "   - Compare slope and aspect calculations at different resolutions\n",
    "   - Determine optimal resolution for your study objectives\n",
    "\n",
    "### 9.2 Advanced Projects\n",
    "\n",
    "1. **Terrain Classification**:\n",
    "   - Implement advanced landform classification algorithms\n",
    "   - Use machine learning to classify terrain types\n",
    "   - Validate classifications against field data or imagery\n",
    "\n",
    "2. **Error Analysis**:\n",
    "   - Implement uncertainty propagation for topographic derivatives\n",
    "   - Analyze how DEM errors affect EEMT calculations\n",
    "   - Develop quality control procedures for your analysis\n",
    "\n",
    "3. **Scale Effects**:\n",
    "   - Investigate how terrain analysis results change with scale\n",
    "   - Implement scale-dependent terrain analysis\n",
    "   - Develop guidelines for appropriate scale selection\n",
    "\n",
    "### 9.3 Real-World Applications\n",
    "\n",
    "1. **Hazard Assessment**:\n",
    "   - Use slope analysis for landslide susceptibility mapping\n",
    "   - Identify flood-prone areas using flow accumulation\n",
    "   - Assess erosion potential from topographic metrics\n",
    "\n",
    "2. **Renewable Energy**:\n",
    "   - Site wind turbines using terrain exposure analysis\n",
    "   - Assess solar potential with topographic solar modeling\n",
    "   - Optimize placement using viewshed analysis\n",
    "\n",
    "3. **Ecosystem Modeling**:\n",
    "   - Use topographic variables to predict species distributions\n",
    "   - Model ecosystem boundaries using terrain analysis\n",
    "   - Assess habitat connectivity across landscapes\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: High-quality elevation data is fundamental to accurate EEMT calculations. Take time to understand your data sources, validate quality, and choose appropriate processing methods for your specific application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}